{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import re\n",
    "from IPython import display\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import bert\n",
    "from tensorflow.keras.models import Model       # Keras is the new high level API for TensorFlow\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Restrict TensorFlow to only use the first GPU\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocess the input sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 5427 vocabularies in total\n",
      "Word to id mapping, for example: flower -> 1\n",
      "Id to word mapping, for example: 1 -> flower\n",
      "Tokens: <PAD>: 5427; <RARE>: 5428\n"
     ]
    }
   ],
   "source": [
    "dictionary_path = './dictionary'\n",
    "vocab = np.load(dictionary_path + '/vocab.npy')\n",
    "print('there are {} vocabularies in total'.format(len(vocab)))\n",
    "\n",
    "word2Id_dict = dict(np.load(dictionary_path + '/word2Id.npy'))\n",
    "id2word_dict = dict(np.load(dictionary_path + '/id2Word.npy'))\n",
    "print('Word to id mapping, for example: %s -> %s' % ('flower', word2Id_dict['flower']))\n",
    "print('Id to word mapping, for example: %s -> %s' % ('1', id2word_dict['1']))\n",
    "print('Tokens: <PAD>: %s; <RARE>: %s' % (word2Id_dict['<PAD>'], word2Id_dict['<RARE>']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the flower shown has yellow anther red pistil and bright red petals.\n",
      "['9', '1', '82', '5', '11', '70', '20', '31', '3', '29', '20', '2', '5427', '5427', '5427', '5427', '5427', '5427', '5427', '5427']\n"
     ]
    }
   ],
   "source": [
    "def sent2IdList(line, MAX_SEQ_LENGTH=20):\n",
    "    MAX_SEQ_LIMIT = MAX_SEQ_LENGTH\n",
    "    padding = 0\n",
    "    \n",
    "    # data preprocessing, remove all puntuation in the texts\n",
    "    prep_line = re.sub('[%s]' % re.escape(string.punctuation), ' ', line.rstrip())\n",
    "    prep_line = prep_line.replace('-', ' ')\n",
    "    prep_line = prep_line.replace('-', ' ')\n",
    "    prep_line = prep_line.replace('  ', ' ')\n",
    "    prep_line = prep_line.replace('.', '')\n",
    "    tokens = prep_line.split(' ')\n",
    "    tokens = [\n",
    "        tokens[i] for i in range(len(tokens))\n",
    "        if tokens[i] != ' ' and tokens[i] != ''\n",
    "    ]\n",
    "    l = len(tokens)\n",
    "    padding = MAX_SEQ_LIMIT - l\n",
    "    \n",
    "    # make sure length of each text is equal to MAX_SEQ_LENGTH, and replace the less common word with <RARE> token\n",
    "    for i in range(padding):\n",
    "        tokens.append('<PAD>')\n",
    "    line = [\n",
    "        word2Id_dict[tokens[k]]\n",
    "        if tokens[k] in word2Id_dict else word2Id_dict['<RARE>']\n",
    "        for k in range(len(tokens))\n",
    "    ]\n",
    "\n",
    "    return line\n",
    "\n",
    "text = \"the flower shown has yellow anther red pistil and bright red petals.\"\n",
    "print(text)\n",
    "print(sent2IdList(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### hyper parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparas = {\n",
    "    'MAX_SEQ_LENGTH': 20,                       # maximum sequence length\n",
    "    'EMBED_DIM': 256,                                  # word embedding dimension\n",
    "    'VOCAB_SIZE': len(word2Id_dict),          # size of dictionary of captions\n",
    "    'RNN_HIDDEN_SIZE': 128,                     # number of RNN neurons\n",
    "    'CODE_DIM':128,                                     # dim of code after both rnn_encoder and cnn_encoder, need to be the same in order to calculate cosine similarity\n",
    "    'DENSE_DIM': 128,                                  # number of neurons in dense layer\n",
    "    'IMAGE_SIZE': [64, 64, 3],                      # render image size\n",
    "    'BATCH_SIZE': 64,\n",
    "    'LR': 1e-4,\n",
    "    'LR_DECAY': 0.5,\n",
    "    'BETA_1': 0.5,\n",
    "    'N_EPOCH': 200,               \n",
    "    'PRINT_FREQ': 1,                                      # printing frequency of loss\n",
    "    'N_SAMPLE': 70504                                    # size of training data\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7370 image in training data\n"
     ]
    }
   ],
   "source": [
    "data_path = './dataset'\n",
    "df = pd.read_pickle(data_path + '/text2ImgData.pkl')\n",
    "num_training_sample = len(df)\n",
    "n_images_train = num_training_sample\n",
    "print('There are %d image in training data' % (n_images_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Captions</th>\n",
       "      <th>ImagePath</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6734</th>\n",
       "      <td>[[9, 2, 17, 9, 1, 6, 14, 13, 18, 3, 41, 8, 11,...</td>\n",
       "      <td>./102flowers/image_06734.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6736</th>\n",
       "      <td>[[4, 1, 5, 12, 2, 3, 11, 31, 28, 68, 106, 132,...</td>\n",
       "      <td>./102flowers/image_06736.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6737</th>\n",
       "      <td>[[9, 2, 27, 4, 1, 6, 14, 7, 12, 19, 5427, 5427...</td>\n",
       "      <td>./102flowers/image_06737.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6738</th>\n",
       "      <td>[[9, 1, 5, 8, 54, 16, 38, 7, 12, 116, 325, 3, ...</td>\n",
       "      <td>./102flowers/image_06738.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6739</th>\n",
       "      <td>[[4, 12, 1, 5, 29, 11, 19, 7, 26, 70, 5427, 54...</td>\n",
       "      <td>./102flowers/image_06739.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Captions  \\\n",
       "ID                                                        \n",
       "6734  [[9, 2, 17, 9, 1, 6, 14, 13, 18, 3, 41, 8, 11,...   \n",
       "6736  [[4, 1, 5, 12, 2, 3, 11, 31, 28, 68, 106, 132,...   \n",
       "6737  [[9, 2, 27, 4, 1, 6, 14, 7, 12, 19, 5427, 5427...   \n",
       "6738  [[9, 1, 5, 8, 54, 16, 38, 7, 12, 116, 325, 3, ...   \n",
       "6739  [[4, 12, 1, 5, 29, 11, 19, 7, 26, 70, 5427, 54...   \n",
       "\n",
       "                         ImagePath  \n",
       "ID                                  \n",
       "6734  ./102flowers/image_06734.jpg  \n",
       "6736  ./102flowers/image_06736.jpg  \n",
       "6737  ./102flowers/image_06737.jpg  \n",
       "6738  ./102flowers/image_06738.jpg  \n",
       "6739  ./102flowers/image_06739.jpg  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions = df['Captions'].values[0]\n",
    "len(captions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We use every sentence (1~10 sentences) corresponding to the image to create the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70504, 20)\n",
      "70504\n"
     ]
    }
   ],
   "source": [
    "filenames = data_path + '/text2ImgData.pkl'\n",
    "\n",
    "# load the training data into two NumPy arrays\n",
    "df = pd.read_pickle(filenames)\n",
    "captions = df['Captions'].values\n",
    "image_paths = df['ImagePath'].values\n",
    "caption = []\n",
    "image_path = []\n",
    "# each image has 1 to 10 corresponding captions\n",
    "# we choose one of them randomly for training\n",
    "for i in range(len(captions)):\n",
    "    im_path = image_paths[i]\n",
    "    for c in captions[i]:\n",
    "        caption.append (c)\n",
    "        image_path.append (im_path)\n",
    "#  caption.append(random.choice(captions[i]))\n",
    "caption = np.asarray(caption)\n",
    "caption = caption.astype(np.int)\n",
    "\n",
    "print(caption.shape)\n",
    "print(len(image_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 'dataset_generator' is the function for creating dataset which uses every sentence corresponding to the image, whereas 'dataset_generator_random' is the function for creating dataset which only randomly picks a sentence from every sentence corresponding to the image. In the final decision, we use 'dataset_generator' for creating dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this competition, you have to generate image in size 64x64x3\n",
    "IMAGE_HEIGHT = 64\n",
    "IMAGE_WIDTH = 64\n",
    "IMAGE_CHANNEL = 3\n",
    "\n",
    "def training_data_generator(caption, image_path):\n",
    "    # load in the image according to image path\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_image(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = (img*2 ) - 1 # -1 to 1\n",
    "    img.set_shape([None, None, 3])\n",
    "    img = tf.image.resize(img, size=[IMAGE_HEIGHT, IMAGE_WIDTH])\n",
    "    img.set_shape([IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNEL])\n",
    "    caption = tf.cast(caption, tf.int32)\n",
    "    return img, caption\n",
    "\n",
    "def dataset_generator(batch_size, data_generator, with_image = True):\n",
    "    # assume that each row of `features` corresponds to the same row as `labels`.\n",
    "    # assert caption.shape[0] == image_path.shape[0]\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((caption, image_path))\n",
    "    dataset = dataset.map(data_generator,    num_parallel_calls=6)\n",
    "    dataset = dataset.shuffle(len(caption)).batch(batch_size, drop_remainder=True)\n",
    "    dataset = dataset.prefetch(buffer_size=5000)\n",
    "    hparas['N_SAMPLE'] = 70504 \n",
    "    return dataset\n",
    "\n",
    "def dataset_generator_random(filenames, batch_size, data_generator):\n",
    "    # load the training data into two NumPy arrays\n",
    "    df = pd.read_pickle(filenames)\n",
    "    captions = df['Captions'].values\n",
    "    caption = []\n",
    "    # each image has 1 to 10 corresponding captions\n",
    "    # we choose one of them randomly for training\n",
    "    for i in range(len(captions)):\n",
    "        caption.append(random.choice(captions[i]))\n",
    "    caption = np.asarray(caption)\n",
    "    caption = caption.astype(np.int)\n",
    "    image_path = df['ImagePath'].values\n",
    "    \n",
    "    # assume that each row of `features` corresponds to the same row as `labels`.\n",
    "    assert caption.shape[0] == image_path.shape[0]\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((caption, image_path))\n",
    "    dataset = dataset.map(data_generator, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(len(caption)).batch(batch_size, drop_remainder=True)\n",
    "    dataset = dataset.prefetch(buffer_size=5000)\n",
    "    # tf.print(caption.shape[0])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fake_dataset is a dataset that help us to create unpaired data examples. Those unpaired data examples are images that paired with wrong captions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_generator(hparas['BATCH_SIZE'] , training_data_generator)\n",
    "fake_dataset = dataset_generator(hparas['BATCH_SIZE']  , training_data_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((64, 64, 64, 3), (64, 20)), types: (tf.float32, tf.int32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_dataset                   # first dimension: batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The RNN encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, LeakyReLU, Conv2DTranspose, GRU, Embedding,Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "class RnnEncoder(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, hparas):\n",
    "        super(RnnEncoder, self).__init__()\n",
    "        self.hparas = hparas\n",
    "        \n",
    "        # params \n",
    "        self.batch_size = self.hparas['BATCH_SIZE']\n",
    "        self.code_dim = self.hparas['CODE_DIM'] \n",
    "\n",
    "        # layers \n",
    "        # shape = (batch_size, max_lenth)\n",
    "        self.embedding = Embedding(self.hparas['VOCAB_SIZE'], self.hparas['EMBED_DIM'])\n",
    "        # shape = (batch_size, max_lenth, embedding_dim)\n",
    "        self.RENet = GRU(self.hparas['RNN_HIDDEN_SIZE'], return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
    "        # shape = (batch_size, rnn_hidden_size)\n",
    "        \n",
    "        # self.dense = Dense(self.code_dim) \n",
    "        \n",
    "    def call(self, text, hidden):\n",
    "        text_embed = self.embedding (text) \n",
    "        whole_sequence_output, final_state = self.RENet(text_embed, initial_state  = hidden)\n",
    "        # whole_sequence_output => shape = (batch_size, 20, RNN_HIDDEN_SIZE)\n",
    "        return whole_sequence_output[:, -1, :]                   # result of the last input\n",
    "    \n",
    "    def initialize_hidden_state(self, current_batch_size ):\n",
    "        # return the initial hidden state \n",
    "        return tf.zeros((current_batch_size, self.hparas['RNN_HIDDEN_SIZE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The CNN encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, LeakyReLU, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "class CnnEncoder(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, hparas):\n",
    "        super(CnnEncoder, self).__init__()\n",
    "        self.hparas = hparas\n",
    "        \n",
    "        # parameter\n",
    "        self.batch_size = self.hparas['BATCH_SIZE']\n",
    "        self.n_filter = 64\n",
    "        self.code_dim = self.hparas['CODE_DIM'] \n",
    "        \n",
    "        # layers \n",
    "        # shape = (batch_size, 64, 64, 3)\n",
    "        self.con1 = Conv2D(filters = self.n_filter* 1 , kernel_size=4,  strides = 2)\n",
    "        self.act1 = LeakyReLU()\n",
    "        # shape = (batch_size, 32, 32, n_filter) \n",
    "        self.con2 = Conv2D(filters = self.n_filter* 2 , kernel_size=4,  strides = 2)\n",
    "        self.bat2 = BatchNormalization()\n",
    "        self.act2 = LeakyReLU()\n",
    "        # shape = (batch_size, 16, 16, n_filter*2) \n",
    "        self.con3 = Conv2D(filters = self.n_filter* 4 , kernel_size=4,  strides = 2)\n",
    "        self.bat3 = BatchNormalization()\n",
    "        self.act3 = LeakyReLU()\n",
    "        # shape = (batch_size, 8, 8, n_filter*4) \n",
    "        self.con4 = Conv2D(filters = self.n_filter* 8 , kernel_size=4,  strides = 2)\n",
    "        self.bat4 = BatchNormalization()\n",
    "        self.act4 = LeakyReLU()\n",
    "        self.flatten = Flatten()\n",
    "        self.dense = Dense(self.code_dim)\n",
    "        # shape = (batch_size, code_dim)\n",
    "        \n",
    "    def call(self, img, training = True):\n",
    "        x = self.con1(img)\n",
    "        x = self.act1(x)\n",
    "\n",
    "        x = self.con2(x)\n",
    "        x = self.bat2(x, training=training)\n",
    "        x = self.act2(x)\n",
    "\n",
    "        x = self.con3(x)\n",
    "        x = self.bat3(x, training=training)\n",
    "        x = self.act3(x)\n",
    "\n",
    "        x = self.con4(x)\n",
    "        x = self.bat4(x, training=training)\n",
    "        x = self.act4(x)\n",
    "        x = self.flatten(x)\n",
    "        img_code = self.dense(x)\n",
    "\n",
    "        return img_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_encoder = CnnEncoder(hparas)\n",
    "rnn_encoder = RnnEncoder(hparas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_optimizer = tf.keras.optimizers.Adam(hparas['LR'])\n",
    "rnn_optimizer = tf.keras.optimizers.Adam(hparas['LR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In our training process, we want to make the output of RNN encoder and CNN encoder as similar as possible. Therefore, we compare the output of RNN encoder and CNN encoder using cosine similarity and calculate the loss. The input and ouput shape is written in comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1, v2):\n",
    "    \"\"\"\n",
    "    cost = (v1 dot v2 ) /( (sqrt (v1 dot v1)*  sqrt (v2  dot v2) ) ) \n",
    "    v1:  shape = (batch_size, code_dim )\n",
    "    v2:  shape = (batch_size, code_dim )\n",
    "    \"\"\"\n",
    "    cost = tf.reduce_sum(tf.multiply(v1, v2), axis=1 ) / ( tf.sqrt(tf.reduce_sum(tf.multiply(v1, v1), axis=1)) * tf.sqrt(tf.reduce_sum(tf.multiply(v2, v2), 1)) )\n",
    "    # tf.print(cost.shape)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step (real_image, real_caption, wrong_image, wrong_caption):\n",
    "    '''\n",
    "        image + caption (pair data)\n",
    "        image + wrong_caption (unpair data)\n",
    "    '''\n",
    "    hidden = rnn_encoder.initialize_hidden_state(real_image.shape[0])                 # real_image[0] = batch_size\n",
    "    \n",
    "    with tf.GradientTape() as cnn_tape, tf.GradientTape() as rnn_tape:\n",
    "        real_ImgCode = cnn_encoder (real_image, training = True)\n",
    "        wrong_ImgCode = cnn_encoder (wrong_image, training = True)\n",
    "        real_CapCode = rnn_encoder (real_caption, hidden)\n",
    "        wrong_CapCode = rnn_encoder (wrong_caption, hidden) \n",
    "    \n",
    "        alpha = 0.2  # margin alpha\n",
    "        loss = tf.reduce_mean(tf.maximum(0., alpha - cosine_similarity(real_ImgCode, real_CapCode) + cosine_similarity(real_ImgCode, wrong_ImgCode))) + \\\n",
    "                   tf.reduce_mean(tf.maximum(0., alpha - cosine_similarity(real_ImgCode, real_CapCode) + cosine_similarity(wrong_ImgCode, real_CapCode)))\n",
    "\n",
    "    # backprop \n",
    "    grad_c = cnn_tape.gradient(loss, cnn_encoder.trainable_variables)\n",
    "    grad_r = rnn_tape.gradient(loss, rnn_encoder.trainable_variables)\n",
    "    \n",
    "    cnn_optimizer.apply_gradients(zip(grad_c, cnn_encoder.trainable_variables))\n",
    "    rnn_optimizer.apply_gradients(zip(grad_r, rnn_encoder.trainable_variables))\n",
    "    \n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint for cnn encoder\n",
    "CNN_CKPT_DIR = './ckpts/cnn_encoder'\n",
    "cnn_ckpt = tf.train.Checkpoint(step=tf.Variable(1), cnn_encoder=cnn_encoder)\n",
    "cnn_ckpt_manager = tf.train.CheckpointManager(cnn_ckpt, CNN_CKPT_DIR, max_to_keep=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint for rnn encoder\n",
    "RNN_CKPT_DIR = './ckpts/rnn_encoder'\n",
    "rnn_ckpt = tf.train.Checkpoint(step=tf.Variable(1), rnn_encoder=rnn_encoder)\n",
    "rnn_ckpt_manager = tf.train.CheckpointManager(rnn_ckpt, RNN_CKPT_DIR, max_to_keep=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0   Time taken for 1 epoch 271 sec   Loss  0.23787 \n",
      "Saved cnn checkpoint for step 0: ./ckpts/cnn_encoder\\ckpt-1\n",
      "Saved rnn checkpoint for step 0: ./ckpts/rnn_encoder\\ckpt-1\n",
      "Epoch   1   Time taken for 1 epoch 276 sec   Loss  0.22433 \n",
      "Saved cnn checkpoint for step 1: ./ckpts/cnn_encoder\\ckpt-2\n",
      "Saved rnn checkpoint for step 1: ./ckpts/rnn_encoder\\ckpt-2\n",
      "Epoch   2   Time taken for 1 epoch 279 sec   Loss  0.13841 \n",
      "Saved cnn checkpoint for step 2: ./ckpts/cnn_encoder\\ckpt-3\n",
      "Saved rnn checkpoint for step 2: ./ckpts/rnn_encoder\\ckpt-3\n",
      "Epoch   3   Time taken for 1 epoch 282 sec   Loss  0.12560 \n",
      "Saved cnn checkpoint for step 3: ./ckpts/cnn_encoder\\ckpt-4\n",
      "Saved rnn checkpoint for step 3: ./ckpts/rnn_encoder\\ckpt-4\n",
      "Epoch   4   Time taken for 1 epoch 281 sec   Loss  0.11429 \n",
      "Saved cnn checkpoint for step 4: ./ckpts/cnn_encoder\\ckpt-5\n",
      "Saved rnn checkpoint for step 4: ./ckpts/rnn_encoder\\ckpt-5\n",
      "Epoch   5   Time taken for 1 epoch 286 sec   Loss  0.08909 \n",
      "Saved cnn checkpoint for step 5: ./ckpts/cnn_encoder\\ckpt-6\n",
      "Saved rnn checkpoint for step 5: ./ckpts/rnn_encoder\\ckpt-6\n",
      "Epoch   6   Time taken for 1 epoch 283 sec   Loss  0.08024 \n",
      "Saved cnn checkpoint for step 6: ./ckpts/cnn_encoder\\ckpt-7\n",
      "Saved rnn checkpoint for step 6: ./ckpts/rnn_encoder\\ckpt-7\n",
      "Epoch   7   Time taken for 1 epoch 283 sec   Loss  0.07574 \n",
      "Saved cnn checkpoint for step 7: ./ckpts/cnn_encoder\\ckpt-8\n",
      "Saved rnn checkpoint for step 7: ./ckpts/rnn_encoder\\ckpt-8\n",
      "Epoch   8   Time taken for 1 epoch 284 sec   Loss  0.07116 \n",
      "Saved cnn checkpoint for step 8: ./ckpts/cnn_encoder\\ckpt-9\n",
      "Saved rnn checkpoint for step 8: ./ckpts/rnn_encoder\\ckpt-9\n",
      "Epoch   9   Time taken for 1 epoch 284 sec   Loss  0.06846 \n",
      "Saved cnn checkpoint for step 9: ./ckpts/cnn_encoder\\ckpt-10\n",
      "Saved rnn checkpoint for step 9: ./ckpts/rnn_encoder\\ckpt-10\n",
      "Epoch  10   Time taken for 1 epoch 284 sec   Loss  0.06598 \n",
      "Saved cnn checkpoint for step 10: ./ckpts/cnn_encoder\\ckpt-11\n",
      "Saved rnn checkpoint for step 10: ./ckpts/rnn_encoder\\ckpt-11\n",
      "Epoch  11   Time taken for 1 epoch 284 sec   Loss  0.06362 \n",
      "Saved cnn checkpoint for step 11: ./ckpts/cnn_encoder\\ckpt-12\n",
      "Saved rnn checkpoint for step 11: ./ckpts/rnn_encoder\\ckpt-12\n",
      "Epoch  12   Time taken for 1 epoch 284 sec   Loss  0.06080 \n",
      "Saved cnn checkpoint for step 12: ./ckpts/cnn_encoder\\ckpt-13\n",
      "Saved rnn checkpoint for step 12: ./ckpts/rnn_encoder\\ckpt-13\n",
      "Epoch  13   Time taken for 1 epoch 284 sec   Loss  0.05989 \n",
      "Saved cnn checkpoint for step 13: ./ckpts/cnn_encoder\\ckpt-14\n",
      "Saved rnn checkpoint for step 13: ./ckpts/rnn_encoder\\ckpt-14\n",
      "Epoch  14   Time taken for 1 epoch 287 sec   Loss  0.05856 \n",
      "Saved cnn checkpoint for step 14: ./ckpts/cnn_encoder\\ckpt-15\n",
      "Saved rnn checkpoint for step 14: ./ckpts/rnn_encoder\\ckpt-15\n",
      "Epoch  15   Time taken for 1 epoch 286 sec   Loss  0.05685 \n",
      "Saved cnn checkpoint for step 15: ./ckpts/cnn_encoder\\ckpt-16\n",
      "Saved rnn checkpoint for step 15: ./ckpts/rnn_encoder\\ckpt-16\n",
      "Epoch  16   Time taken for 1 epoch 284 sec   Loss  0.05469 \n",
      "Saved cnn checkpoint for step 16: ./ckpts/cnn_encoder\\ckpt-17\n",
      "Saved rnn checkpoint for step 16: ./ckpts/rnn_encoder\\ckpt-17\n",
      "Epoch  17   Time taken for 1 epoch 286 sec   Loss  0.05268 \n",
      "Saved cnn checkpoint for step 17: ./ckpts/cnn_encoder\\ckpt-18\n",
      "Saved rnn checkpoint for step 17: ./ckpts/rnn_encoder\\ckpt-18\n",
      "Epoch  18   Time taken for 1 epoch 286 sec   Loss  0.05204 \n",
      "Saved cnn checkpoint for step 18: ./ckpts/cnn_encoder\\ckpt-19\n",
      "Saved rnn checkpoint for step 18: ./ckpts/rnn_encoder\\ckpt-19\n",
      "Epoch  19   Time taken for 1 epoch 287 sec   Loss  0.05031 \n",
      "Saved cnn checkpoint for step 19: ./ckpts/cnn_encoder\\ckpt-20\n",
      "Saved rnn checkpoint for step 19: ./ckpts/rnn_encoder\\ckpt-20\n",
      "Epoch  20   Time taken for 1 epoch 286 sec   Loss  0.04922 \n",
      "Saved cnn checkpoint for step 20: ./ckpts/cnn_encoder\\ckpt-21\n",
      "Saved rnn checkpoint for step 20: ./ckpts/rnn_encoder\\ckpt-21\n",
      "Epoch  21   Time taken for 1 epoch 287 sec   Loss  0.04854 \n",
      "Saved cnn checkpoint for step 21: ./ckpts/cnn_encoder\\ckpt-22\n",
      "Saved rnn checkpoint for step 21: ./ckpts/rnn_encoder\\ckpt-22\n",
      "Epoch  22   Time taken for 1 epoch 288 sec   Loss  0.04587 \n",
      "Saved cnn checkpoint for step 22: ./ckpts/cnn_encoder\\ckpt-23\n",
      "Saved rnn checkpoint for step 22: ./ckpts/rnn_encoder\\ckpt-23\n",
      "Epoch  23   Time taken for 1 epoch 287 sec   Loss  0.04527 \n",
      "Saved cnn checkpoint for step 23: ./ckpts/cnn_encoder\\ckpt-24\n",
      "Saved rnn checkpoint for step 23: ./ckpts/rnn_encoder\\ckpt-24\n",
      "Epoch  24   Time taken for 1 epoch 288 sec   Loss  0.04436 \n",
      "Saved cnn checkpoint for step 24: ./ckpts/cnn_encoder\\ckpt-25\n",
      "Saved rnn checkpoint for step 24: ./ckpts/rnn_encoder\\ckpt-25\n",
      "Epoch  25   Time taken for 1 epoch 287 sec   Loss  0.04288 \n",
      "Saved cnn checkpoint for step 25: ./ckpts/cnn_encoder\\ckpt-26\n",
      "Saved rnn checkpoint for step 25: ./ckpts/rnn_encoder\\ckpt-26\n",
      "Epoch  26   Time taken for 1 epoch 287 sec   Loss  0.04256 \n",
      "Saved cnn checkpoint for step 26: ./ckpts/cnn_encoder\\ckpt-27\n",
      "Saved rnn checkpoint for step 26: ./ckpts/rnn_encoder\\ckpt-27\n",
      "Epoch  27   Time taken for 1 epoch 287 sec   Loss  0.04148 \n",
      "Saved cnn checkpoint for step 27: ./ckpts/cnn_encoder\\ckpt-28\n",
      "Saved rnn checkpoint for step 27: ./ckpts/rnn_encoder\\ckpt-28\n",
      "Epoch  28   Time taken for 1 epoch 289 sec   Loss  0.04062 \n",
      "Saved cnn checkpoint for step 28: ./ckpts/cnn_encoder\\ckpt-29\n",
      "Saved rnn checkpoint for step 28: ./ckpts/rnn_encoder\\ckpt-29\n",
      "Epoch  29   Time taken for 1 epoch 286 sec   Loss  0.04021 \n",
      "Saved cnn checkpoint for step 29: ./ckpts/cnn_encoder\\ckpt-30\n",
      "Saved rnn checkpoint for step 29: ./ckpts/rnn_encoder\\ckpt-30\n",
      "Epoch  30   Time taken for 1 epoch 288 sec   Loss  0.03955 \n",
      "Saved cnn checkpoint for step 30: ./ckpts/cnn_encoder\\ckpt-31\n",
      "Saved rnn checkpoint for step 30: ./ckpts/rnn_encoder\\ckpt-31\n",
      "Epoch  31   Time taken for 1 epoch 289 sec   Loss  0.03954 \n",
      "Saved cnn checkpoint for step 31: ./ckpts/cnn_encoder\\ckpt-32\n",
      "Saved rnn checkpoint for step 31: ./ckpts/rnn_encoder\\ckpt-32\n",
      "Epoch  32   Time taken for 1 epoch 287 sec   Loss  0.03780 \n",
      "Saved cnn checkpoint for step 32: ./ckpts/cnn_encoder\\ckpt-33\n",
      "Saved rnn checkpoint for step 32: ./ckpts/rnn_encoder\\ckpt-33\n",
      "Epoch  33   Time taken for 1 epoch 288 sec   Loss  0.03826 \n",
      "Saved cnn checkpoint for step 33: ./ckpts/cnn_encoder\\ckpt-34\n",
      "Saved rnn checkpoint for step 33: ./ckpts/rnn_encoder\\ckpt-34\n",
      "Epoch  34   Time taken for 1 epoch 288 sec   Loss  0.03722 \n",
      "Saved cnn checkpoint for step 34: ./ckpts/cnn_encoder\\ckpt-35\n",
      "Saved rnn checkpoint for step 34: ./ckpts/rnn_encoder\\ckpt-35\n",
      "Epoch  35   Time taken for 1 epoch 288 sec   Loss  0.03695 \n",
      "Saved cnn checkpoint for step 35: ./ckpts/cnn_encoder\\ckpt-36\n",
      "Saved rnn checkpoint for step 35: ./ckpts/rnn_encoder\\ckpt-36\n",
      "Epoch  36   Time taken for 1 epoch 288 sec   Loss  0.03640 \n",
      "Saved cnn checkpoint for step 36: ./ckpts/cnn_encoder\\ckpt-37\n",
      "Saved rnn checkpoint for step 36: ./ckpts/rnn_encoder\\ckpt-37\n",
      "Epoch  37   Time taken for 1 epoch 289 sec   Loss  0.03549 \n",
      "Saved cnn checkpoint for step 37: ./ckpts/cnn_encoder\\ckpt-38\n",
      "Saved rnn checkpoint for step 37: ./ckpts/rnn_encoder\\ckpt-38\n",
      "Epoch  38   Time taken for 1 epoch 290 sec   Loss  0.03505 \n",
      "Saved cnn checkpoint for step 38: ./ckpts/cnn_encoder\\ckpt-39\n",
      "Saved rnn checkpoint for step 38: ./ckpts/rnn_encoder\\ckpt-39\n",
      "Epoch  39   Time taken for 1 epoch 288 sec   Loss  0.03517 \n",
      "Saved cnn checkpoint for step 39: ./ckpts/cnn_encoder\\ckpt-40\n",
      "Saved rnn checkpoint for step 39: ./ckpts/rnn_encoder\\ckpt-40\n",
      "Epoch  40   Time taken for 1 epoch 293 sec   Loss  0.03390 \n",
      "Saved cnn checkpoint for step 40: ./ckpts/cnn_encoder\\ckpt-41\n",
      "Saved rnn checkpoint for step 40: ./ckpts/rnn_encoder\\ckpt-41\n",
      "Epoch  41   Time taken for 1 epoch 290 sec   Loss  0.03366 \n",
      "Saved cnn checkpoint for step 41: ./ckpts/cnn_encoder\\ckpt-42\n",
      "Saved rnn checkpoint for step 41: ./ckpts/rnn_encoder\\ckpt-42\n",
      "Epoch  42   Time taken for 1 epoch 291 sec   Loss  0.03278 \n",
      "Saved cnn checkpoint for step 42: ./ckpts/cnn_encoder\\ckpt-43\n",
      "Saved rnn checkpoint for step 42: ./ckpts/rnn_encoder\\ckpt-43\n",
      "Epoch  43   Time taken for 1 epoch 292 sec   Loss  0.03250 \n",
      "Saved cnn checkpoint for step 43: ./ckpts/cnn_encoder\\ckpt-44\n",
      "Saved rnn checkpoint for step 43: ./ckpts/rnn_encoder\\ckpt-44\n",
      "Epoch  44   Time taken for 1 epoch 292 sec   Loss  0.03191 \n",
      "Saved cnn checkpoint for step 44: ./ckpts/cnn_encoder\\ckpt-45\n",
      "Saved rnn checkpoint for step 44: ./ckpts/rnn_encoder\\ckpt-45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  45   Time taken for 1 epoch 292 sec   Loss  0.03131 \n",
      "Saved cnn checkpoint for step 45: ./ckpts/cnn_encoder\\ckpt-46\n",
      "Saved rnn checkpoint for step 45: ./ckpts/rnn_encoder\\ckpt-46\n",
      "Epoch  46   Time taken for 1 epoch 293 sec   Loss  0.03182 \n",
      "Saved cnn checkpoint for step 46: ./ckpts/cnn_encoder\\ckpt-47\n",
      "Saved rnn checkpoint for step 46: ./ckpts/rnn_encoder\\ckpt-47\n",
      "Epoch  47   Time taken for 1 epoch 292 sec   Loss  0.03167 \n",
      "Saved cnn checkpoint for step 47: ./ckpts/cnn_encoder\\ckpt-48\n",
      "Saved rnn checkpoint for step 47: ./ckpts/rnn_encoder\\ckpt-48\n",
      "Epoch  48   Time taken for 1 epoch 292 sec   Loss  0.03112 \n",
      "Saved cnn checkpoint for step 48: ./ckpts/cnn_encoder\\ckpt-49\n",
      "Saved rnn checkpoint for step 48: ./ckpts/rnn_encoder\\ckpt-49\n",
      "Epoch  49   Time taken for 1 epoch 293 sec   Loss  0.03043 \n",
      "Saved cnn checkpoint for step 49: ./ckpts/cnn_encoder\\ckpt-50\n",
      "Saved rnn checkpoint for step 49: ./ckpts/rnn_encoder\\ckpt-50\n",
      "Epoch  50   Time taken for 1 epoch 292 sec   Loss  0.03036 \n",
      "Saved cnn checkpoint for step 50: ./ckpts/cnn_encoder\\ckpt-51\n",
      "Saved rnn checkpoint for step 50: ./ckpts/rnn_encoder\\ckpt-51\n",
      "Epoch  51   Time taken for 1 epoch 291 sec   Loss  0.03007 \n",
      "Saved cnn checkpoint for step 51: ./ckpts/cnn_encoder\\ckpt-52\n",
      "Saved rnn checkpoint for step 51: ./ckpts/rnn_encoder\\ckpt-52\n",
      "Epoch  52   Time taken for 1 epoch 292 sec   Loss  0.02911 \n",
      "Saved cnn checkpoint for step 52: ./ckpts/cnn_encoder\\ckpt-53\n",
      "Saved rnn checkpoint for step 52: ./ckpts/rnn_encoder\\ckpt-53\n",
      "Epoch  53   Time taken for 1 epoch 293 sec   Loss  0.02893 \n",
      "Saved cnn checkpoint for step 53: ./ckpts/cnn_encoder\\ckpt-54\n",
      "Saved rnn checkpoint for step 53: ./ckpts/rnn_encoder\\ckpt-54\n",
      "Epoch  54   Time taken for 1 epoch 292 sec   Loss  0.02898 \n",
      "Saved cnn checkpoint for step 54: ./ckpts/cnn_encoder\\ckpt-55\n",
      "Saved rnn checkpoint for step 54: ./ckpts/rnn_encoder\\ckpt-55\n",
      "Epoch  55   Time taken for 1 epoch 292 sec   Loss  0.02825 \n",
      "Saved cnn checkpoint for step 55: ./ckpts/cnn_encoder\\ckpt-56\n",
      "Saved rnn checkpoint for step 55: ./ckpts/rnn_encoder\\ckpt-56\n",
      "Epoch  56   Time taken for 1 epoch 293 sec   Loss  0.02810 \n",
      "Saved cnn checkpoint for step 56: ./ckpts/cnn_encoder\\ckpt-57\n",
      "Saved rnn checkpoint for step 56: ./ckpts/rnn_encoder\\ckpt-57\n",
      "Epoch  57   Time taken for 1 epoch 293 sec   Loss  0.02792 \n",
      "Saved cnn checkpoint for step 57: ./ckpts/cnn_encoder\\ckpt-58\n",
      "Saved rnn checkpoint for step 57: ./ckpts/rnn_encoder\\ckpt-58\n",
      "Epoch  58   Time taken for 1 epoch 293 sec   Loss  0.02771 \n",
      "Saved cnn checkpoint for step 58: ./ckpts/cnn_encoder\\ckpt-59\n",
      "Saved rnn checkpoint for step 58: ./ckpts/rnn_encoder\\ckpt-59\n",
      "Epoch  59   Time taken for 1 epoch 293 sec   Loss  0.02731 \n",
      "Saved cnn checkpoint for step 59: ./ckpts/cnn_encoder\\ckpt-60\n",
      "Saved rnn checkpoint for step 59: ./ckpts/rnn_encoder\\ckpt-60\n",
      "Epoch  60   Time taken for 1 epoch 292 sec   Loss  0.02708 \n",
      "Saved cnn checkpoint for step 60: ./ckpts/cnn_encoder\\ckpt-61\n",
      "Saved rnn checkpoint for step 60: ./ckpts/rnn_encoder\\ckpt-61\n",
      "Epoch  61   Time taken for 1 epoch 293 sec   Loss  0.02723 \n",
      "Saved cnn checkpoint for step 61: ./ckpts/cnn_encoder\\ckpt-62\n",
      "Saved rnn checkpoint for step 61: ./ckpts/rnn_encoder\\ckpt-62\n",
      "Epoch  62   Time taken for 1 epoch 293 sec   Loss  0.02628 \n",
      "Saved cnn checkpoint for step 62: ./ckpts/cnn_encoder\\ckpt-63\n",
      "Saved rnn checkpoint for step 62: ./ckpts/rnn_encoder\\ckpt-63\n",
      "Epoch  63   Time taken for 1 epoch 291 sec   Loss  0.02639 \n",
      "Saved cnn checkpoint for step 63: ./ckpts/cnn_encoder\\ckpt-64\n",
      "Saved rnn checkpoint for step 63: ./ckpts/rnn_encoder\\ckpt-64\n",
      "Epoch  64   Time taken for 1 epoch 293 sec   Loss  0.02627 \n",
      "Saved cnn checkpoint for step 64: ./ckpts/cnn_encoder\\ckpt-65\n",
      "Saved rnn checkpoint for step 64: ./ckpts/rnn_encoder\\ckpt-65\n",
      "Epoch  65   Time taken for 1 epoch 293 sec   Loss  0.02599 \n",
      "Saved cnn checkpoint for step 65: ./ckpts/cnn_encoder\\ckpt-66\n",
      "Saved rnn checkpoint for step 65: ./ckpts/rnn_encoder\\ckpt-66\n",
      "Epoch  66   Time taken for 1 epoch 292 sec   Loss  0.02566 \n",
      "Saved cnn checkpoint for step 66: ./ckpts/cnn_encoder\\ckpt-67\n",
      "Saved rnn checkpoint for step 66: ./ckpts/rnn_encoder\\ckpt-67\n",
      "Epoch  67   Time taken for 1 epoch 292 sec   Loss  0.02559 \n",
      "Saved cnn checkpoint for step 67: ./ckpts/cnn_encoder\\ckpt-68\n",
      "Saved rnn checkpoint for step 67: ./ckpts/rnn_encoder\\ckpt-68\n",
      "Epoch  68   Time taken for 1 epoch 293 sec   Loss  0.02547 \n",
      "Saved cnn checkpoint for step 68: ./ckpts/cnn_encoder\\ckpt-69\n",
      "Saved rnn checkpoint for step 68: ./ckpts/rnn_encoder\\ckpt-69\n",
      "Epoch  69   Time taken for 1 epoch 294 sec   Loss  0.02518 \n",
      "Saved cnn checkpoint for step 69: ./ckpts/cnn_encoder\\ckpt-70\n",
      "Saved rnn checkpoint for step 69: ./ckpts/rnn_encoder\\ckpt-70\n",
      "Epoch  70   Time taken for 1 epoch 293 sec   Loss  0.02502 \n",
      "Saved cnn checkpoint for step 70: ./ckpts/cnn_encoder\\ckpt-71\n",
      "Saved rnn checkpoint for step 70: ./ckpts/rnn_encoder\\ckpt-71\n",
      "Epoch  71   Time taken for 1 epoch 294 sec   Loss  0.02453 \n",
      "Saved cnn checkpoint for step 71: ./ckpts/cnn_encoder\\ckpt-72\n",
      "Saved rnn checkpoint for step 71: ./ckpts/rnn_encoder\\ckpt-72\n",
      "Epoch  72   Time taken for 1 epoch 294 sec   Loss  0.02459 \n",
      "Saved cnn checkpoint for step 72: ./ckpts/cnn_encoder\\ckpt-73\n",
      "Saved rnn checkpoint for step 72: ./ckpts/rnn_encoder\\ckpt-73\n",
      "Epoch  73   Time taken for 1 epoch 294 sec   Loss  0.02437 \n",
      "Saved cnn checkpoint for step 73: ./ckpts/cnn_encoder\\ckpt-74\n",
      "Saved rnn checkpoint for step 73: ./ckpts/rnn_encoder\\ckpt-74\n",
      "Epoch  74   Time taken for 1 epoch 294 sec   Loss  0.02387 \n",
      "Saved cnn checkpoint for step 74: ./ckpts/cnn_encoder\\ckpt-75\n",
      "Saved rnn checkpoint for step 74: ./ckpts/rnn_encoder\\ckpt-75\n",
      "Epoch  75   Time taken for 1 epoch 294 sec   Loss  0.02388 \n",
      "Saved cnn checkpoint for step 75: ./ckpts/cnn_encoder\\ckpt-76\n",
      "Saved rnn checkpoint for step 75: ./ckpts/rnn_encoder\\ckpt-76\n",
      "Epoch  76   Time taken for 1 epoch 294 sec   Loss  0.02413 \n",
      "Saved cnn checkpoint for step 76: ./ckpts/cnn_encoder\\ckpt-77\n",
      "Saved rnn checkpoint for step 76: ./ckpts/rnn_encoder\\ckpt-77\n",
      "Epoch  77   Time taken for 1 epoch 294 sec   Loss  0.02349 \n",
      "Saved cnn checkpoint for step 77: ./ckpts/cnn_encoder\\ckpt-78\n",
      "Saved rnn checkpoint for step 77: ./ckpts/rnn_encoder\\ckpt-78\n",
      "Epoch  78   Time taken for 1 epoch 294 sec   Loss  0.02294 \n",
      "Saved cnn checkpoint for step 78: ./ckpts/cnn_encoder\\ckpt-79\n",
      "Saved rnn checkpoint for step 78: ./ckpts/rnn_encoder\\ckpt-79\n",
      "Epoch  79   Time taken for 1 epoch 294 sec   Loss  0.02287 \n",
      "Saved cnn checkpoint for step 79: ./ckpts/cnn_encoder\\ckpt-80\n",
      "Saved rnn checkpoint for step 79: ./ckpts/rnn_encoder\\ckpt-80\n",
      "Epoch  80   Time taken for 1 epoch 294 sec   Loss  0.02268 \n",
      "Saved cnn checkpoint for step 80: ./ckpts/cnn_encoder\\ckpt-81\n",
      "Saved rnn checkpoint for step 80: ./ckpts/rnn_encoder\\ckpt-81\n",
      "Epoch  81   Time taken for 1 epoch 294 sec   Loss  0.02246 \n",
      "Saved cnn checkpoint for step 81: ./ckpts/cnn_encoder\\ckpt-82\n",
      "Saved rnn checkpoint for step 81: ./ckpts/rnn_encoder\\ckpt-82\n",
      "Epoch  82   Time taken for 1 epoch 294 sec   Loss  0.02273 \n",
      "Saved cnn checkpoint for step 82: ./ckpts/cnn_encoder\\ckpt-83\n",
      "Saved rnn checkpoint for step 82: ./ckpts/rnn_encoder\\ckpt-83\n",
      "Epoch  83   Time taken for 1 epoch 294 sec   Loss  0.02233 \n",
      "Saved cnn checkpoint for step 83: ./ckpts/cnn_encoder\\ckpt-84\n",
      "Saved rnn checkpoint for step 83: ./ckpts/rnn_encoder\\ckpt-84\n",
      "Epoch  84   Time taken for 1 epoch 294 sec   Loss  0.02221 \n",
      "Saved cnn checkpoint for step 84: ./ckpts/cnn_encoder\\ckpt-85\n",
      "Saved rnn checkpoint for step 84: ./ckpts/rnn_encoder\\ckpt-85\n",
      "Epoch  85   Time taken for 1 epoch 294 sec   Loss  0.02187 \n",
      "Saved cnn checkpoint for step 85: ./ckpts/cnn_encoder\\ckpt-86\n",
      "Saved rnn checkpoint for step 85: ./ckpts/rnn_encoder\\ckpt-86\n",
      "Epoch  86   Time taken for 1 epoch 294 sec   Loss  0.02228 \n",
      "Saved cnn checkpoint for step 86: ./ckpts/cnn_encoder\\ckpt-87\n",
      "Saved rnn checkpoint for step 86: ./ckpts/rnn_encoder\\ckpt-87\n",
      "Epoch  87   Time taken for 1 epoch 293 sec   Loss  0.02221 \n",
      "Saved cnn checkpoint for step 87: ./ckpts/cnn_encoder\\ckpt-88\n",
      "Saved rnn checkpoint for step 87: ./ckpts/rnn_encoder\\ckpt-88\n",
      "Epoch  88   Time taken for 1 epoch 292 sec   Loss  0.02145 \n",
      "Saved cnn checkpoint for step 88: ./ckpts/cnn_encoder\\ckpt-89\n",
      "Saved rnn checkpoint for step 88: ./ckpts/rnn_encoder\\ckpt-89\n",
      "Epoch  89   Time taken for 1 epoch 294 sec   Loss  0.02145 \n",
      "Saved cnn checkpoint for step 89: ./ckpts/cnn_encoder\\ckpt-90\n",
      "Saved rnn checkpoint for step 89: ./ckpts/rnn_encoder\\ckpt-90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  90   Time taken for 1 epoch 293 sec   Loss  0.02126 \n",
      "Saved cnn checkpoint for step 90: ./ckpts/cnn_encoder\\ckpt-91\n",
      "Saved rnn checkpoint for step 90: ./ckpts/rnn_encoder\\ckpt-91\n",
      "Epoch  91   Time taken for 1 epoch 293 sec   Loss  0.02093 \n",
      "Saved cnn checkpoint for step 91: ./ckpts/cnn_encoder\\ckpt-92\n",
      "Saved rnn checkpoint for step 91: ./ckpts/rnn_encoder\\ckpt-92\n",
      "Epoch  92   Time taken for 1 epoch 293 sec   Loss  0.02102 \n",
      "Saved cnn checkpoint for step 92: ./ckpts/cnn_encoder\\ckpt-93\n",
      "Saved rnn checkpoint for step 92: ./ckpts/rnn_encoder\\ckpt-93\n",
      "Epoch  93   Time taken for 1 epoch 295 sec   Loss  0.02088 \n",
      "Saved cnn checkpoint for step 93: ./ckpts/cnn_encoder\\ckpt-94\n",
      "Saved rnn checkpoint for step 93: ./ckpts/rnn_encoder\\ckpt-94\n",
      "Epoch  94   Time taken for 1 epoch 294 sec   Loss  0.02032 \n",
      "Saved cnn checkpoint for step 94: ./ckpts/cnn_encoder\\ckpt-95\n",
      "Saved rnn checkpoint for step 94: ./ckpts/rnn_encoder\\ckpt-95\n",
      "Epoch  95   Time taken for 1 epoch 294 sec   Loss  0.02033 \n",
      "Saved cnn checkpoint for step 95: ./ckpts/cnn_encoder\\ckpt-96\n",
      "Saved rnn checkpoint for step 95: ./ckpts/rnn_encoder\\ckpt-96\n",
      "Epoch  96   Time taken for 1 epoch 294 sec   Loss  0.02023 \n",
      "Saved cnn checkpoint for step 96: ./ckpts/cnn_encoder\\ckpt-97\n",
      "Saved rnn checkpoint for step 96: ./ckpts/rnn_encoder\\ckpt-97\n",
      "Epoch  97   Time taken for 1 epoch 294 sec   Loss  0.02012 \n",
      "Saved cnn checkpoint for step 97: ./ckpts/cnn_encoder\\ckpt-98\n",
      "Saved rnn checkpoint for step 97: ./ckpts/rnn_encoder\\ckpt-98\n",
      "Epoch  98   Time taken for 1 epoch 295 sec   Loss  0.02031 \n",
      "Saved cnn checkpoint for step 98: ./ckpts/cnn_encoder\\ckpt-99\n",
      "Saved rnn checkpoint for step 98: ./ckpts/rnn_encoder\\ckpt-99\n",
      "Epoch  99   Time taken for 1 epoch 295 sec   Loss  0.02074 \n",
      "Saved cnn checkpoint for step 99: ./ckpts/cnn_encoder\\ckpt-100\n",
      "Saved rnn checkpoint for step 99: ./ckpts/rnn_encoder\\ckpt-100\n",
      "Epoch 100   Time taken for 1 epoch 296 sec   Loss  0.02005 \n",
      "Saved cnn checkpoint for step 100: ./ckpts/cnn_encoder\\ckpt-101\n",
      "Saved rnn checkpoint for step 100: ./ckpts/rnn_encoder\\ckpt-101\n",
      "Epoch 101   Time taken for 1 epoch 295 sec   Loss  0.01954 \n",
      "Saved cnn checkpoint for step 101: ./ckpts/cnn_encoder\\ckpt-102\n",
      "Saved rnn checkpoint for step 101: ./ckpts/rnn_encoder\\ckpt-102\n",
      "Epoch 102   Time taken for 1 epoch 294 sec   Loss  0.01982 \n",
      "Saved cnn checkpoint for step 102: ./ckpts/cnn_encoder\\ckpt-103\n",
      "Saved rnn checkpoint for step 102: ./ckpts/rnn_encoder\\ckpt-103\n",
      "Epoch 103   Time taken for 1 epoch 294 sec   Loss  0.01928 \n",
      "Saved cnn checkpoint for step 103: ./ckpts/cnn_encoder\\ckpt-104\n",
      "Saved rnn checkpoint for step 103: ./ckpts/rnn_encoder\\ckpt-104\n",
      "Epoch 104   Time taken for 1 epoch 295 sec   Loss  0.01912 \n",
      "Saved cnn checkpoint for step 104: ./ckpts/cnn_encoder\\ckpt-105\n",
      "Saved rnn checkpoint for step 104: ./ckpts/rnn_encoder\\ckpt-105\n",
      "Epoch 105   Time taken for 1 epoch 295 sec   Loss  0.01933 \n",
      "Saved cnn checkpoint for step 105: ./ckpts/cnn_encoder\\ckpt-106\n",
      "Saved rnn checkpoint for step 105: ./ckpts/rnn_encoder\\ckpt-106\n",
      "Epoch 106   Time taken for 1 epoch 295 sec   Loss  0.01931 \n",
      "Saved cnn checkpoint for step 106: ./ckpts/cnn_encoder\\ckpt-107\n",
      "Saved rnn checkpoint for step 106: ./ckpts/rnn_encoder\\ckpt-107\n",
      "Epoch 107   Time taken for 1 epoch 290 sec   Loss  0.01885 \n",
      "Saved cnn checkpoint for step 107: ./ckpts/cnn_encoder\\ckpt-108\n",
      "Saved rnn checkpoint for step 107: ./ckpts/rnn_encoder\\ckpt-108\n",
      "Epoch 108   Time taken for 1 epoch 295 sec   Loss  0.01890 \n",
      "Saved cnn checkpoint for step 108: ./ckpts/cnn_encoder\\ckpt-109\n",
      "Saved rnn checkpoint for step 108: ./ckpts/rnn_encoder\\ckpt-109\n",
      "Epoch 109   Time taken for 1 epoch 295 sec   Loss  0.01872 \n",
      "Saved cnn checkpoint for step 109: ./ckpts/cnn_encoder\\ckpt-110\n",
      "Saved rnn checkpoint for step 109: ./ckpts/rnn_encoder\\ckpt-110\n",
      "Epoch 110   Time taken for 1 epoch 294 sec   Loss  0.01860 \n",
      "Saved cnn checkpoint for step 110: ./ckpts/cnn_encoder\\ckpt-111\n",
      "Saved rnn checkpoint for step 110: ./ckpts/rnn_encoder\\ckpt-111\n",
      "Epoch 111   Time taken for 1 epoch 294 sec   Loss  0.01903 \n",
      "Saved cnn checkpoint for step 111: ./ckpts/cnn_encoder\\ckpt-112\n",
      "Saved rnn checkpoint for step 111: ./ckpts/rnn_encoder\\ckpt-112\n",
      "Epoch 112   Time taken for 1 epoch 294 sec   Loss  0.01829 \n",
      "Saved cnn checkpoint for step 112: ./ckpts/cnn_encoder\\ckpt-113\n",
      "Saved rnn checkpoint for step 112: ./ckpts/rnn_encoder\\ckpt-113\n",
      "Epoch 113   Time taken for 1 epoch 294 sec   Loss  0.01795 \n",
      "Saved cnn checkpoint for step 113: ./ckpts/cnn_encoder\\ckpt-114\n",
      "Saved rnn checkpoint for step 113: ./ckpts/rnn_encoder\\ckpt-114\n",
      "Epoch 114   Time taken for 1 epoch 295 sec   Loss  0.01845 \n",
      "Saved cnn checkpoint for step 114: ./ckpts/cnn_encoder\\ckpt-115\n",
      "Saved rnn checkpoint for step 114: ./ckpts/rnn_encoder\\ckpt-115\n",
      "Epoch 115   Time taken for 1 epoch 293 sec   Loss  0.01803 \n",
      "Saved cnn checkpoint for step 115: ./ckpts/cnn_encoder\\ckpt-116\n",
      "Saved rnn checkpoint for step 115: ./ckpts/rnn_encoder\\ckpt-116\n",
      "Epoch 116   Time taken for 1 epoch 294 sec   Loss  0.01784 \n",
      "Saved cnn checkpoint for step 116: ./ckpts/cnn_encoder\\ckpt-117\n",
      "Saved rnn checkpoint for step 116: ./ckpts/rnn_encoder\\ckpt-117\n",
      "Epoch 117   Time taken for 1 epoch 295 sec   Loss  0.01789 \n",
      "Saved cnn checkpoint for step 117: ./ckpts/cnn_encoder\\ckpt-118\n",
      "Saved rnn checkpoint for step 117: ./ckpts/rnn_encoder\\ckpt-118\n",
      "Epoch 118   Time taken for 1 epoch 294 sec   Loss  0.01749 \n",
      "Saved cnn checkpoint for step 118: ./ckpts/cnn_encoder\\ckpt-119\n",
      "Saved rnn checkpoint for step 118: ./ckpts/rnn_encoder\\ckpt-119\n",
      "Epoch 119   Time taken for 1 epoch 293 sec   Loss  0.01773 \n",
      "Saved cnn checkpoint for step 119: ./ckpts/cnn_encoder\\ckpt-120\n",
      "Saved rnn checkpoint for step 119: ./ckpts/rnn_encoder\\ckpt-120\n",
      "Epoch 120   Time taken for 1 epoch 294 sec   Loss  0.01754 \n",
      "Saved cnn checkpoint for step 120: ./ckpts/cnn_encoder\\ckpt-121\n",
      "Saved rnn checkpoint for step 120: ./ckpts/rnn_encoder\\ckpt-121\n",
      "Epoch 121   Time taken for 1 epoch 294 sec   Loss  0.01751 \n",
      "Saved cnn checkpoint for step 121: ./ckpts/cnn_encoder\\ckpt-122\n",
      "Saved rnn checkpoint for step 121: ./ckpts/rnn_encoder\\ckpt-122\n",
      "Epoch 122   Time taken for 1 epoch 294 sec   Loss  0.01697 \n",
      "Saved cnn checkpoint for step 122: ./ckpts/cnn_encoder\\ckpt-123\n",
      "Saved rnn checkpoint for step 122: ./ckpts/rnn_encoder\\ckpt-123\n",
      "Epoch 123   Time taken for 1 epoch 295 sec   Loss  0.01775 \n",
      "Saved cnn checkpoint for step 123: ./ckpts/cnn_encoder\\ckpt-124\n",
      "Saved rnn checkpoint for step 123: ./ckpts/rnn_encoder\\ckpt-124\n",
      "Epoch 124   Time taken for 1 epoch 296 sec   Loss  0.01718 \n",
      "Saved cnn checkpoint for step 124: ./ckpts/cnn_encoder\\ckpt-125\n",
      "Saved rnn checkpoint for step 124: ./ckpts/rnn_encoder\\ckpt-125\n",
      "Epoch 125   Time taken for 1 epoch 296 sec   Loss  0.01698 \n",
      "Saved cnn checkpoint for step 125: ./ckpts/cnn_encoder\\ckpt-126\n",
      "Saved rnn checkpoint for step 125: ./ckpts/rnn_encoder\\ckpt-126\n",
      "Epoch 126   Time taken for 1 epoch 296 sec   Loss  0.01708 \n",
      "Saved cnn checkpoint for step 126: ./ckpts/cnn_encoder\\ckpt-127\n",
      "Saved rnn checkpoint for step 126: ./ckpts/rnn_encoder\\ckpt-127\n",
      "Epoch 127   Time taken for 1 epoch 295 sec   Loss  0.01648 \n",
      "Saved cnn checkpoint for step 127: ./ckpts/cnn_encoder\\ckpt-128\n",
      "Saved rnn checkpoint for step 127: ./ckpts/rnn_encoder\\ckpt-128\n",
      "Epoch 128   Time taken for 1 epoch 295 sec   Loss  0.01687 \n",
      "Saved cnn checkpoint for step 128: ./ckpts/cnn_encoder\\ckpt-129\n",
      "Saved rnn checkpoint for step 128: ./ckpts/rnn_encoder\\ckpt-129\n",
      "Epoch 129   Time taken for 1 epoch 296 sec   Loss  0.01697 \n",
      "Saved cnn checkpoint for step 129: ./ckpts/cnn_encoder\\ckpt-130\n",
      "Saved rnn checkpoint for step 129: ./ckpts/rnn_encoder\\ckpt-130\n",
      "Epoch 130   Time taken for 1 epoch 296 sec   Loss  0.01669 \n",
      "Saved cnn checkpoint for step 130: ./ckpts/cnn_encoder\\ckpt-131\n",
      "Saved rnn checkpoint for step 130: ./ckpts/rnn_encoder\\ckpt-131\n",
      "Epoch 131   Time taken for 1 epoch 295 sec   Loss  0.01678 \n",
      "Saved cnn checkpoint for step 131: ./ckpts/cnn_encoder\\ckpt-132\n",
      "Saved rnn checkpoint for step 131: ./ckpts/rnn_encoder\\ckpt-132\n",
      "Epoch 132   Time taken for 1 epoch 295 sec   Loss  0.01577 \n",
      "Saved cnn checkpoint for step 132: ./ckpts/cnn_encoder\\ckpt-133\n",
      "Saved rnn checkpoint for step 132: ./ckpts/rnn_encoder\\ckpt-133\n",
      "Epoch 133   Time taken for 1 epoch 296 sec   Loss  0.01627 \n",
      "Saved cnn checkpoint for step 133: ./ckpts/cnn_encoder\\ckpt-134\n",
      "Saved rnn checkpoint for step 133: ./ckpts/rnn_encoder\\ckpt-134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134   Time taken for 1 epoch 296 sec   Loss  0.01657 \n",
      "Saved cnn checkpoint for step 134: ./ckpts/cnn_encoder\\ckpt-135\n",
      "Saved rnn checkpoint for step 134: ./ckpts/rnn_encoder\\ckpt-135\n",
      "Epoch 135   Time taken for 1 epoch 296 sec   Loss  0.01606 \n",
      "Saved cnn checkpoint for step 135: ./ckpts/cnn_encoder\\ckpt-136\n",
      "Saved rnn checkpoint for step 135: ./ckpts/rnn_encoder\\ckpt-136\n",
      "Epoch 136   Time taken for 1 epoch 296 sec   Loss  0.01588 \n",
      "Saved cnn checkpoint for step 136: ./ckpts/cnn_encoder\\ckpt-137\n",
      "Saved rnn checkpoint for step 136: ./ckpts/rnn_encoder\\ckpt-137\n",
      "Epoch 137   Time taken for 1 epoch 296 sec   Loss  0.01590 \n",
      "Saved cnn checkpoint for step 137: ./ckpts/cnn_encoder\\ckpt-138\n",
      "Saved rnn checkpoint for step 137: ./ckpts/rnn_encoder\\ckpt-138\n",
      "Epoch 138   Time taken for 1 epoch 296 sec   Loss  0.01602 \n",
      "Saved cnn checkpoint for step 138: ./ckpts/cnn_encoder\\ckpt-139\n",
      "Saved rnn checkpoint for step 138: ./ckpts/rnn_encoder\\ckpt-139\n",
      "Epoch 139   Time taken for 1 epoch 296 sec   Loss  0.01552 \n",
      "Saved cnn checkpoint for step 139: ./ckpts/cnn_encoder\\ckpt-140\n",
      "Saved rnn checkpoint for step 139: ./ckpts/rnn_encoder\\ckpt-140\n",
      "Epoch 140   Time taken for 1 epoch 295 sec   Loss  0.01574 \n",
      "Saved cnn checkpoint for step 140: ./ckpts/cnn_encoder\\ckpt-141\n",
      "Saved rnn checkpoint for step 140: ./ckpts/rnn_encoder\\ckpt-141\n",
      "Epoch 141   Time taken for 1 epoch 296 sec   Loss  0.01598 \n",
      "Saved cnn checkpoint for step 141: ./ckpts/cnn_encoder\\ckpt-142\n",
      "Saved rnn checkpoint for step 141: ./ckpts/rnn_encoder\\ckpt-142\n",
      "Epoch 142   Time taken for 1 epoch 295 sec   Loss  0.01550 \n",
      "Saved cnn checkpoint for step 142: ./ckpts/cnn_encoder\\ckpt-143\n",
      "Saved rnn checkpoint for step 142: ./ckpts/rnn_encoder\\ckpt-143\n",
      "Epoch 143   Time taken for 1 epoch 295 sec   Loss  0.01549 \n",
      "Saved cnn checkpoint for step 143: ./ckpts/cnn_encoder\\ckpt-144\n",
      "Saved rnn checkpoint for step 143: ./ckpts/rnn_encoder\\ckpt-144\n",
      "Epoch 144   Time taken for 1 epoch 295 sec   Loss  0.01558 \n",
      "Saved cnn checkpoint for step 144: ./ckpts/cnn_encoder\\ckpt-145\n",
      "Saved rnn checkpoint for step 144: ./ckpts/rnn_encoder\\ckpt-145\n",
      "Epoch 145   Time taken for 1 epoch 295 sec   Loss  0.01563 \n",
      "Saved cnn checkpoint for step 145: ./ckpts/cnn_encoder\\ckpt-146\n",
      "Saved rnn checkpoint for step 145: ./ckpts/rnn_encoder\\ckpt-146\n",
      "Epoch 146   Time taken for 1 epoch 295 sec   Loss  0.01498 \n",
      "Saved cnn checkpoint for step 146: ./ckpts/cnn_encoder\\ckpt-147\n",
      "Saved rnn checkpoint for step 146: ./ckpts/rnn_encoder\\ckpt-147\n",
      "Epoch 147   Time taken for 1 epoch 299 sec   Loss  0.01495 \n",
      "Saved cnn checkpoint for step 147: ./ckpts/cnn_encoder\\ckpt-148\n",
      "Saved rnn checkpoint for step 147: ./ckpts/rnn_encoder\\ckpt-148\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-18306dd6b7cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mreal_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_caption\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrong_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrong_caption\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfake_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_caption\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrong_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrong_caption\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    734\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# For Python 3 compatibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_next_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    770\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    771\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 772\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    773\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    774\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;31m# and instead mimic ops placement in graphs: Operations on resource\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m         \u001b[1;31m# handles execute on the same device as where the resource is placed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 755\u001b[1;33m         ret = gen_dataset_ops.iterator_get_next(\n\u001b[0m\u001b[0;32m    756\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m             \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   2602\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2603\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2604\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   2605\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"IteratorGetNext\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2606\u001b[0m         \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"output_types\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_epoch = 0\n",
    "steps_per_epoch = int(hparas['N_SAMPLE'] / hparas['BATCH_SIZE'])\n",
    "encoder_loss = []\n",
    "for ep in range (hparas['N_EPOCH']):\n",
    "    start_time = time.time()\n",
    "\n",
    "    total_loss = 0\n",
    "    \n",
    "    # dataset = dataset_generator(data_path + '/text2ImgData.pkl', hparas['BATCH_SIZE'] , training_data_generator)\n",
    "    # fake_dataset = dataset_generator(data_path + '/text2ImgData.pkl', hparas['BATCH_SIZE']  , training_data_generator)\n",
    "    \n",
    "    \n",
    "    for (real_image, real_caption),(wrong_image, wrong_caption) in zip(dataset, fake_dataset):\n",
    "        loss = train_step(real_image, real_caption, wrong_image, wrong_caption)\n",
    "        total_loss += loss.numpy() \n",
    "    total_loss = total_loss / steps_per_epoch\n",
    "    encoder_loss.append(total_loss)\n",
    "    print (\"Epoch %3d   Time taken for 1 epoch %d sec   Loss % .5f \" % (ep,  time.time() - start_time, total_loss )) \n",
    "    \n",
    "    # save checkpoint for each epoch\n",
    "    if ep % 1 == 0:\n",
    "        save_path = cnn_ckpt_manager.save()\n",
    "        print(\"Saved cnn checkpoint for step {}: {}\".format(ep, save_path))\n",
    "        save_path = rnn_ckpt_manager.save()\n",
    "        print(\"Saved rnn checkpoint for step {}: {}\".format(ep, save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### After training for 148 epochs, our loss is 0.01495. Then, we use this encoder to train conditional gan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In testing, we check whether our text encoder can get high cosine similarity if the inputs are paired image and caption. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "dataset = dataset_generator(data_path + '/text2ImgData.pkl', hparas['BATCH_SIZE'], training_data_generator)\n",
    "fake_dataset = dataset_generator(data_path + '/text2ImgData.pkl', hparas['BATCH_SIZE'], training_data_generator)\n",
    "\n",
    "\n",
    "for (real_image, real_caption),(wrong_image, wrong_caption) in zip(dataset, fake_dataset):\n",
    "    hidden = rnn_encoder.initialize_hidden_state(real_image.shape[0])\n",
    "\n",
    "    real_ImgCode = cnn_encoder (real_image, training = False)\n",
    "    wrong_ImgCode = cnn_encoder (wrong_image, training = False)\n",
    "    real_CapCode = rnn_encoder (real_caption, hidden)\n",
    "    wrong_CapCode = rnn_encoder (wrong_caption, hidden)\n",
    "    tf.print(tf.reduce_sum(cosine_similarity(real_ImgCode,real_CapCode),0)/hparas['BATCH_SIZE'])\n",
    "    tf.print(tf.reduce_sum(cosine_similarity(real_ImgCode,wrong_CapCode),0)/hparas['BATCH_SIZE'])\n",
    "    tf.print(tf.reduce_sum(cosine_similarity(wrong_ImgCode,real_CapCode),0)/hparas['BATCH_SIZE'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
